{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1d8ccf",
   "metadata": {},
   "source": [
    "# ðŸ§¹ Data Cleaning Project: Big Five Personality Dataset.\n",
    "\n",
    "This is a project to show a full data cleaning workflow on a large dataset with around 1M rows. the goal is to produce clean and analysis ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754ad8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
      "0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...   \n",
      "1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...   \n",
      "2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...   \n",
      "3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...   \n",
      "4   3.0   3.0   3.0   3.0   5.0   3.0   3.0   5.0   3.0    4.0  ...   \n",
      "\n",
      "              dateload  screenw  screenh  introelapse  testelapse  endelapse  \\\n",
      "0  2016-03-03 02:01:01    768.0   1024.0          9.0       234.0          6   \n",
      "1  2016-03-03 02:01:20   1360.0    768.0         12.0       179.0         11   \n",
      "2  2016-03-03 02:01:56   1366.0    768.0          3.0       186.0          7   \n",
      "3  2016-03-03 02:02:02   1920.0   1200.0        186.0       219.0          7   \n",
      "4  2016-03-03 02:02:57   1366.0    768.0          8.0       315.0         17   \n",
      "\n",
      "   IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
      "0    1       GB               51.5448                 0.1991  \n",
      "1    1       MY                3.1698                101.706  \n",
      "2    1       GB               54.9119                -1.3833  \n",
      "3    1       GB                 51.75                  -1.25  \n",
      "4    2       KE                   1.0                   38.0  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load the dataset\n",
    "file_path = \"/Users/mona.moghadam@schibsted.com/Desktop/portfolio, data cleaning/data-final.csv\"\n",
    "data = pd.read_csv(file_path, sep= '\\t')\n",
    "#Quick look at the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7a7d8",
   "metadata": {},
   "source": [
    "# Initial Data Exploration\n",
    "-check basic information\n",
    "-Look for missing values\n",
    "-Undrestand data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb20540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1015341 entries, 0 to 1015340\n",
      "Columns: 110 entries, EXT1 to long_appx_lots_of_err\n",
      "dtypes: float64(104), int64(2), object(4)\n",
      "memory usage: 852.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#check basic information\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38848055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT1                     1783\n",
      "EXT2                     1783\n",
      "EXT3                     1783\n",
      "EXT4                     1783\n",
      "EXT5                     1783\n",
      "                         ... \n",
      "endelapse                   0\n",
      "IPC                         0\n",
      "country                    77\n",
      "lat_appx_lots_of_err        0\n",
      "long_appx_lots_of_err       0\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Look for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a668eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT1</th>\n",
       "      <th>EXT2</th>\n",
       "      <th>EXT3</th>\n",
       "      <th>EXT4</th>\n",
       "      <th>EXT5</th>\n",
       "      <th>EXT6</th>\n",
       "      <th>EXT7</th>\n",
       "      <th>EXT8</th>\n",
       "      <th>EXT9</th>\n",
       "      <th>EXT10</th>\n",
       "      <th>...</th>\n",
       "      <th>dateload</th>\n",
       "      <th>screenw</th>\n",
       "      <th>screenh</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>endelapse</th>\n",
       "      <th>IPC</th>\n",
       "      <th>country</th>\n",
       "      <th>lat_appx_lots_of_err</th>\n",
       "      <th>long_appx_lots_of_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38081</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-04-03 10:41:52</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>40.064</td>\n",
       "      <td>-80.7209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662465</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21 05:01:36</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>CY</td>\n",
       "      <td>35.1667</td>\n",
       "      <td>33.3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683996</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-04-02 17:05:34</td>\n",
       "      <td>1536.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>41.9847</td>\n",
       "      <td>-88.0798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757876</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-05-23 17:20:47</td>\n",
       "      <td>412.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>41.7804</td>\n",
       "      <td>-87.6027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908331</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-11 03:56:57</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>IE</td>\n",
       "      <td>53.3478</td>\n",
       "      <td>-6.2597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
       "38081    5.0   1.0   3.0   1.0   4.0   2.0   5.0   5.0   1.0    3.0  ...   \n",
       "662465   4.0   3.0   4.0   3.0   3.0   4.0   3.0   4.0   3.0    3.0  ...   \n",
       "683996   3.0   5.0   2.0   5.0   1.0   3.0   1.0   3.0   3.0    1.0  ...   \n",
       "757876   1.0   5.0   1.0   5.0   1.0   4.0   1.0   5.0   2.0    5.0  ...   \n",
       "908331   5.0   1.0   5.0   5.0   5.0   1.0   5.0   5.0   5.0    3.0  ...   \n",
       "\n",
       "                   dateload  screenw  screenh  introelapse  testelapse  \\\n",
       "38081   2016-04-03 10:41:52   1440.0    900.0          3.0       161.0   \n",
       "662465  2018-03-21 05:01:36   1920.0   1080.0          2.0       320.0   \n",
       "683996  2018-04-02 17:05:34   1536.0    864.0         45.0       136.0   \n",
       "757876  2018-05-23 17:20:47    412.0    732.0          4.0       427.0   \n",
       "908331  2018-09-11 03:56:57    768.0   1024.0          3.0       384.0   \n",
       "\n",
       "        endelapse  IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
       "38081          12    1       US                40.064               -80.7209  \n",
       "662465         18    1       CY               35.1667                33.3667  \n",
       "683996         11    1       US               41.9847               -88.0798  \n",
       "757876         12    2       US               41.7804               -87.6027  \n",
       "908331         14   43       IE               53.3478                -6.2597  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undrestad data types\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c2589d",
   "metadata": {},
   "source": [
    "# Data Cleaning:\n",
    "\n",
    "## 1. Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6f42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/xl2p1y_d5hjfmd70sn4y94lr0000gn/T/ipykernel_46736/718640259.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['country'].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill missing countries with Unknown\n",
    "data['country'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e794f9d",
   "metadata": {},
   "source": [
    "## 2. Dropping Incomplete Survey Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab2a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows:  1013558\n"
     ]
    }
   ],
   "source": [
    "#remove rows with missing answers\n",
    "survey_cols = [col for col in data.columns if col.startswith(('EXT', 'EST', 'AGR', 'CSN', 'OPN'))]\n",
    "data.dropna(subset= survey_cols, inplace = True)\n",
    "print('Remaining rows: ', len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bd24b",
   "metadata": {},
   "source": [
    "## 3. Converting Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 'dateload' to datetime\n",
    "data['dateload'] = pd.to_datetime(data['dateload'], errors='coerce')\n",
    "data.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b4749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat_appx_lots_of_err     float64\n",
      "long_appx_lots_of_err    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convert latitude and longitude to numeric values\n",
    "data['lat_appx_lots_of_err'] = pd.to_numeric(data['lat_appx_lots_of_err'], errors = 'coerce')\n",
    "data['long_appx_lots_of_err'] = pd.to_numeric(data['long_appx_lots_of_err'], errors = 'coerce')\n",
    "\n",
    "print(data[['lat_appx_lots_of_err', 'long_appx_lots_of_err']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a92034",
   "metadata": {},
   "source": [
    "# Final Data Validation:\n",
    "- Check missing values\n",
    "- Confirm data types\n",
    "- Sample final rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a8174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT1                         0\n",
      "EXT2                         0\n",
      "EXT3                         0\n",
      "EXT4                         0\n",
      "EXT5                         0\n",
      "                         ...  \n",
      "endelapse                    0\n",
      "IPC                          0\n",
      "country                      0\n",
      "lat_appx_lots_of_err     13721\n",
      "long_appx_lots_of_err    13721\n",
      "Length: 110, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for missing values after cleaning\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235f43c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXT1                     float64\n",
      "EXT2                     float64\n",
      "EXT3                     float64\n",
      "EXT4                     float64\n",
      "EXT5                     float64\n",
      "                          ...   \n",
      "endelapse                  int64\n",
      "IPC                        int64\n",
      "country                   object\n",
      "lat_appx_lots_of_err     float64\n",
      "long_appx_lots_of_err    float64\n",
      "Length: 110, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Confirm data types after cleaning\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3037189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  \\\n",
      "259050   4.0   4.0   4.0   2.0   3.0   2.0   4.0   3.0   4.0    2.0  ...   \n",
      "973388   4.0   2.0   4.0   2.0   4.0   2.0   4.0   4.0   4.0    2.0  ...   \n",
      "496694   3.0   3.0   4.0   3.0   4.0   2.0   2.0   3.0   4.0    2.0  ...   \n",
      "278418   1.0   5.0   1.0   5.0   1.0   5.0   1.0   5.0   2.0    5.0  ...   \n",
      "448317   2.0   3.0   3.0   3.0   3.0   4.0   2.0   4.0   2.0    3.0  ...   \n",
      "\n",
      "                   dateload  screenw  screenh  introelapse  testelapse  \\\n",
      "259050  2016-11-06 16:07:11   1920.0   1080.0          3.0       399.0   \n",
      "973388  2018-10-17 07:19:26   1280.0    720.0         23.0       295.0   \n",
      "496694  2017-09-24 13:09:14   1280.0    800.0         88.0       341.0   \n",
      "278418  2016-11-30 03:52:34   1440.0    900.0          4.0       204.0   \n",
      "448317  2017-07-10 11:08:40    768.0   1024.0          2.0       119.0   \n",
      "\n",
      "        endelapse  IPC  country  lat_appx_lots_of_err  long_appx_lots_of_err  \n",
      "259050        213    1       US               32.2738              -106.7472  \n",
      "973388         22    1       US               38.0000               -97.0000  \n",
      "496694         18    1       SE               59.3294                18.0686  \n",
      "278418         11    1       NO               59.9500                10.7500  \n",
      "448317          7   69       US               47.2875              -122.1094  \n",
      "\n",
      "[5 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "#sample final rows of clean data\n",
    "print(data.sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b6164",
   "metadata": {},
   "source": [
    "# Save the Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07617630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"/Users/mona.moghadam@schibsted.com/Desktop/portfolio, data cleaning/data-final_cleaned.csv\", index=False)\n",
    "print(\"âœ… Cleaned data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e641b",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Summary of Cleaning\n",
    "\n",
    "- Loaded raw tab-separated survey dataset (1M+ entries)\n",
    "- Filled missing values for 'country'\n",
    "- Dropped 1,783 incomplete survey responses\n",
    "- Converted dates and geographical coordinates to correct formats\n",
    "- Verified clean, complete dataset\n",
    "- Final dataset ready for analysis or modeling\n",
    "\n",
    "Tools used: **Python, Pandas, Jupyter Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
